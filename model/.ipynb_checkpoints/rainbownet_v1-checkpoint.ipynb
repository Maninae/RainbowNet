{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5hTe35ToN7tF"
   },
   "outputs": [],
   "source": [
    "# Sources\n",
    "# --------\n",
    "# Emil Wallner blog post and code on Floydhub for image colorization\n",
    "# \"Deep Koalarization\": https://github.com/baldassarreFe/deep-koalarization\n",
    "# \"Colorful Image Colorization\": https://github.com/richzhang/colorization\n",
    "#Todo: Remove this line once it is installed, reset the kernel: Menu > Kernel > Reset & Clear Output\n",
    "# !git clone https://github.com/fchollet/keras.git && cd keras && python setup.py install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 236,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 271,
     "status": "error",
     "timestamp": 1510812387125,
     "user": {
      "displayName": "Cindy Lin",
      "photoUrl": "//lh6.googleusercontent.com/-QZtXpumhTbo/AAAAAAAAAAI/AAAAAAAAMg8/iIMleBruZm0/s50-c-k-no/photo.jpg",
      "userId": "102365799180351563010"
     },
     "user_tz": 480
    },
    "id": "ljuCQQRi_0A_",
    "outputId": "c3e7f92f-bcbd-4cad-98af-3cef58a46f84"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "\n",
    "import matplotlib\n",
    "# This line was for some of our machines; some edge case\n",
    "# matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pickle\n",
    "\n",
    "import keras\n",
    "# import keras.backend as K\n",
    "from keras.layers.core import RepeatVector\n",
    "# Not sure we need all of these\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, merge, concatenate, Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "eBcisdtLBovS"
   },
   "outputs": [],
   "source": [
    "# Paths and utilities\n",
    "# -------------------\n",
    "data_dir = \"../data/\"\n",
    "train_dir = data_dir + \"train/\"\n",
    "test_dir = data_dir + \"test/\"\n",
    "results_dir = \"../results/\"\n",
    "\n",
    "model_chkpt = \"model_params/\"\n",
    "model_name = \"rainbownet\"\n",
    "\n",
    "# Adjustable constants\n",
    "BATCH_SIZE = 16\n",
    "N_EPOCHS = 1\n",
    "NUM_BUCKETS = 259\n",
    "GRID_SIZE = 10\n",
    "\n",
    "# Python 3 peculiarities\n",
    "if sys.version_info[0] == 3:\n",
    "    xrange = range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TjbsQR3aK_cU"
   },
   "source": [
    "## Helper Functions\n",
    "Stuff we're using in the other functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "9Ha_1ZZqLFXy"
   },
   "outputs": [],
   "source": [
    "def resize_images(images, shape):\n",
    "  \"\"\" Does exactly what it sounds like it does.\n",
    "      |shape|: a 3-tuple of the dimensions to resize to. \n",
    "               (H, W, 3) usually.\n",
    "  \"\"\"\n",
    "  resized = []\n",
    "  for i in images:\n",
    "    im = resize(im, shape, mode='constant')\n",
    "    resized.append(im)\n",
    "  resized = np.array(resized)\n",
    "  return resized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MfgjGUVkkqEx"
   },
   "source": [
    "## **The Inception ResNet Fusion**\n",
    "\n",
    "We're going to be using Google's Inception ResNet v2 to augment our CNN. This model has been highly trained on millions of examples, and can detect features that would be useful in colorizing our test images. The fusion of IRNet features with our CNN will come later in RainbowNetModel(). For now, these functions load the model and set up predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "mRJoYEaRAjkl"
   },
   "outputs": [],
   "source": [
    "def load_inception_net():\n",
    "  inception = InceptionResNetV2(weights=None, include_top=True)\n",
    "  inception.load_weights(data_dir + 'inception_resnet_v2_weights.h5')\n",
    "  inception.graph = tf.get_default_graph()\n",
    "  return inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "1fh3CRW0EY-p"
   },
   "outputs": [],
   "source": [
    "def create_inception_embedding(grayscaled_rgb):\n",
    "  \"\"\" One forward pass through the InceptionResNet for one image,\n",
    "      to give said image a 1000-vector embedding of it's features.\n",
    "      \n",
    "      |grayscaled_rgb|: the images we are embedding in grayscale. \n",
    "      \n",
    "      :return: (None, 1000) vector.\n",
    "  \"\"\"\n",
    "  # Resize all the images to (299, 299, 3).\n",
    "  grayscaled_rgb_resized = resize_images(grayscaled_rgb, (299, 299, 3))\n",
    "\n",
    "  # preprocessing for the Inception resnet\n",
    "  grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n",
    "\n",
    "  # Predict.\n",
    "  with inception.graph.as_default():\n",
    "    embed = inception.predict(grayscaled_rgb_resized)\n",
    "  \n",
    "  return embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ISwY0HA1lsh2"
   },
   "source": [
    "## Finding our color buckets\n",
    "This is how we discretized the *ab* channels' color space into buckets for our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "WyvXuOITeoT0"
   },
   "outputs": [],
   "source": [
    "xrange = range\n",
    "\n",
    "def discretize_lab():\n",
    "    print(\"Building original mapping\")\n",
    "    bucket2ab_map = {} # index = bucket #, bucket2ab_map[index] = (a, b)\n",
    "    bucket_count = 0\n",
    "    for a in xrange(-128, 128, GRID_SIZE):\n",
    "        for b in xrange(-128, 128, GRID_SIZE):\n",
    "            a_mid = float(a + GRID_SIZE / 2)\n",
    "            b_mid = float(b + GRID_SIZE / 2)\n",
    "            bucket2ab_map[bucket_count] = (a_mid, b_mid)\n",
    "            bucket_count += 1\n",
    "    \n",
    "    # Invert bucket2ab_map\n",
    "    ab2bucket_map = {ab_pair : bucket for \\\n",
    "                     bucket, ab_pair in bucket2ab_map.items()}\n",
    "    for bucket in bucket2ab_map:\n",
    "        assert ab2bucket_map[bucket2ab_map[bucket]] == bucket\n",
    "\n",
    "    return bucket2ab_map, ab2bucket_map\n",
    "\n",
    "def get_bucket(lab_pixel, ab2bucket_map):\n",
    "    a = int(lab_pixel[1])\n",
    "    b = int(lab_pixel[2])\n",
    "\n",
    "    # -128 through -119 maps to -123\n",
    "    a_mid = GRID_SIZE * ((a + 128) // GRID_SIZE) - 128 + GRID_SIZE / 2\n",
    "    b_mid = GRID_SIZE * ((b + 128) // GRID_SIZE) - 128 + GRID_SIZE / 2\n",
    "\n",
    "    assert (a_mid, b_mid) in ab2bucket_map\n",
    "    return ab2bucket_map[(a_mid, b_mid)]\n",
    "\n",
    "def find_nonzero_buckets(bucket2ab_map, ab2bucket_map):\n",
    "    print(\"Getting bucket counts\")\n",
    "    bucket_counts = [0] * len(bucket2ab_map)\n",
    "    buckets = set()\n",
    "    all_pixels = []\n",
    "    for r in xrange(0, 256, 3):\n",
    "        for g in xrange(0, 256, 2):\n",
    "            for b in xrange(0, 256, 3):\n",
    "                rgb_pixel = np.array([r/255., g/255., b/255.])\n",
    "                all_pixels.append([rgb_pixel])\n",
    "    lab_pixels = rgb2lab(all_pixels)\n",
    "    for i in xrange(len(lab_pixels)):\n",
    "        for j in xrange(len(lab_pixels[0])):\n",
    "            lab_pixel = lab_pixels[i][j]\n",
    "            bucket = get_bucket(lab_pixel, ab2bucket_map)\n",
    "            bucket_counts[bucket] += 1\n",
    "\n",
    "    print(\"Building updated mapping\")\n",
    "    new_bucket2ab_map = {}\n",
    "    for i in xrange(len(bucket_counts)):\n",
    "        if bucket_counts[i] > 0:\n",
    "            new_bucket2ab_map[i] = bucket2ab_map[i]\n",
    "\n",
    "    new_ab2bucket_map = {ab_pair : bucket for \\\n",
    "                         bucket, ab_pair in new_bucket2ab_map.items()}\n",
    "\n",
    "    print(\"There are %d buckets.\" % len(new_bucket2ab_map))\n",
    "    return new_bucket2ab_map, new_ab2bucket_map\n",
    "\n",
    "def plot_mapping(bucket2ab_map):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, aspect='equal')\n",
    "    for bucket in bucket2ab_map:\n",
    "        a_mid = bucket2ab_map[bucket][0]\n",
    "        a_low = a_mid - GRID_SIZE / 2\n",
    "        b_mid = bucket2ab_map[bucket][1]\n",
    "        b_low = b_mid - GRID_SIZE / 2\n",
    "\n",
    "        lab_pixel = np.array([50., a_mid, b_mid])\n",
    "        lab_pixel = np.reshape(lab_pixel, (1, 1, 3))\n",
    "        rgb = tuple(lab2rgb(lab_pixel)[0][0])\n",
    "\n",
    "        ax.add_patch(\n",
    "            patches.Rectangle(\n",
    "                (b_low, -a_low), \n",
    "                GRID_SIZE, \n",
    "                GRID_SIZE, \n",
    "                facecolor=rgb\n",
    "            )\n",
    "        )\n",
    "\n",
    "    plt.xlim([-128, 128])\n",
    "    plt.ylim([-128, 128])\n",
    "    plt.show()\n",
    "\n",
    "def get_buckets():\n",
    "    bucket2ab_map, ab2bucket_map = discretize_lab()\n",
    "    return find_nonzero_buckets(bucket2ab_map, ab2bucket_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "llvS3JwH-8Lo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading buckets from pickle.\n",
      "Buckets loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Loading our bucket maps.\n",
    "\"\"\"\n",
    "\n",
    "# To open: `map = pickle.load(open(<filename>, 'r'))`\n",
    "BUCKET2AB = 'bucket2ab_map.pkl'\n",
    "AB2BUCKET = 'ab2bucket_map.pkl'\n",
    "\n",
    "bucket2ab_map = None\n",
    "ab2bucket_map = None\n",
    "\n",
    "if not os.path.isfile(BUCKET2AB) or not os.path.isfile(AB2BUCKET):\n",
    "  bucket2ab_map, ab2bucket_map = get_buckets()\n",
    "\n",
    "  plot_demo = False  \n",
    "  if plot_demo:\n",
    "    plot_mapping(bucket2ab_map)\n",
    "  \n",
    "  pickle.dump(bucket2ab_map, open(BUCKET2AB, 'wb'))\n",
    "  pickle.dump(ab2bucket_map, open(AB2BUCKET, 'wb'))\n",
    "  \n",
    "else:\n",
    "  print(\"Loading buckets from pickle.\")\n",
    "  bucket2ab_map = pickle.load(open(BUCKET2AB, 'rb'))\n",
    "  ab2bucket_map = pickle.load(open(AB2BUCKET, 'rb'))\n",
    "  \n",
    "if NUM_BUCKETS != len(bucket2ab_map):\n",
    "  print(\"NUM_BUCKETS= %s does not match the number of buckets found.\"\n",
    "        % str(NUM_BUCKETS))\n",
    "  print(\"Setting NUM_BUCKETS=%d\" % len(bucket2ab_map))\n",
    "  NUM_BUCKETS = len(bucket2ab_map)\n",
    "\n",
    "print(\"Buckets loaded successfully!\")\n",
    "\n",
    "# bucket2ab_map: map of bucket # to (a, b)\n",
    "# ab2bucket_map: map of (a, b) to bucket #\n",
    "# use get_bucket(lab_pixel, ab2bucketmap) to get corresponding (a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "_-1k44vKGtu3"
   },
   "outputs": [],
   "source": [
    "def discretize(images_ab):\n",
    "  \"\"\" This is a preprocessing step, that will be used in converting \n",
    "      Y (ab image true labels) into buckets, so that we can calculate\n",
    "      a loss in colorization_loss().\n",
    "  \n",
    "      |images_ab|: (m, H, W, 2) array representing ab channels of images.\n",
    "  \n",
    "      :return: (m, H, W) array where each entry is in [0, NUM_BUCKETS].\n",
    "               One of the NUM_BUCKETS=259 color buckets we found.\n",
    "  \"\"\"\n",
    "  m, H, W, _ = images_ab.shape\n",
    "  images_d = np.zeros((m, H, W))\n",
    "\n",
    "  for i in xrange(m):\n",
    "    for h in xrange(H):\n",
    "      for w in xrange(W):\n",
    "        (a,b) = images_ab[i,h,w]\n",
    "        images_d[i,h,w] = ab2bucket_map[(a,b)]\n",
    "  \n",
    "  return images_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ZvamQXbWhFYz"
   },
   "outputs": [],
   "source": [
    "# This function will be called when we want to demo a predicted image.\n",
    "# It takes an image with pixels labeled with buckets, and transforms it\n",
    "#   into 2 color channels.\n",
    "\n",
    "def inverse_discretize(images_d):\n",
    "  \"\"\" The inverse of the above function. Maps the indicated bucket to\n",
    "      the mean of that bucket.\n",
    "      \n",
    "      |images_d|: an array (m,H,W) with the color bucket assigned to each\n",
    "                  pixel.\n",
    "                  \n",
    "      :return: (m, H, W, 2) array with ab color values.\"\"\"\n",
    "  m, H, W = images_d.shape\n",
    "  images_ab = np.zeros((m, H, W, 2))\n",
    "  \n",
    "  for i in xrange(m):\n",
    "    for h in xrange(H):\n",
    "      for w in xrange(W):\n",
    "        bucket = images_d[i,h,w]\n",
    "        images_ab[i,h,w] = bucket2ab_map[bucket] # Sets to [a,b]\n",
    "  \n",
    "  return images_ab\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NASk5-4fv6wy"
   },
   "source": [
    "## Getting the data\n",
    "This function loads the data, for training and for test.\n",
    "\n",
    "```preprocess_data()``` then processes them for input into our CNN. This involves converting to *Lab* and separating the channels, running through InceptionResnet, and normalizing the *L* channel input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "gjrKq1-pCWC2"
   },
   "outputs": [],
   "source": [
    "# Examples of use:\n",
    "# load_data(train_dir)\n",
    "# load_data(test_dir)\n",
    "\n",
    "def load_data(directory):\n",
    "  \"\"\" Load an entire set of |m| examples. If loading entire dataset takes\n",
    "      too much memory, may have to run in batches: \n",
    "      train, save chkpt.\n",
    "      Put new examples in the directory.\n",
    "      Repeat. \n",
    "  \"\"\"\n",
    "  images = []\n",
    "  for filename in os.listdir(directory):\n",
    "      image = load_img(directory + filename)  # PIL image\n",
    "      images.append(img_to_array(image))      # np.array\n",
    "\n",
    "  images = np.array(images, dtype=float)\n",
    "  return images\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "fjFTS5AOQPYW"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(images):\n",
    "  \"\"\" Preprocess the data for input into our rainbownet model.\n",
    "  \"\"\"\n",
    "  # Resize them to (224,224)\n",
    "  images_resized = resize_images(images, (224, 224, 3))\n",
    "  \n",
    "  # Get the inception embeddings from grayscaled images. \n",
    "  #   This will be part of our passed in input.\n",
    "  grayscaled_images = gray2rgb_vec(rgb2gray_vec(images_resized))\n",
    "  embs = create_inception_embedding(grayscaled_images) # already vec'd\n",
    "  \n",
    "  rgb2gray_vec = np.vectorize(rgb2gray)\n",
    "  gray2rgb_vec = np.vectorize(gray2rgb)  \n",
    "  rgb2lab_vec = np.vectorize(rgb2lab)\n",
    "  \n",
    "  # Separate the l- and ab- channels\n",
    "  images_lab = rgb2lab_vec(images)\n",
    "  images_l = images_lab[:,:,:,0]        # first channel is L\n",
    "  images_ab = images_lab[:,:,:,1:]      # second 2, ab channels\n",
    "  \n",
    "  # Normalize L channel to be between 0, 1.\n",
    "  pass\n",
    "  \n",
    "  # Create X, composed of L channel + the embedding\n",
    "  X = zip(images_l, embs)         # tuple: (m, H, W), (m, 1000)\n",
    "  \n",
    "  # Create Y, including discretizing the ab image\n",
    "  Y = discretize(images_ab)    # shape (m, H, W)\n",
    "  \n",
    "  return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sK7ROlEzwCaz"
   },
   "source": [
    "## Defining our loss\n",
    "Our colorization loss is the softmax cross-entropy between the multinomial color distributions of every pixel in ```y_true``` and ```y_pred``` over all pixels (H,W), over all images in the minibatch. Inspired by the colorization paper, to solve issues other losses like MSE face.\n",
    "\n",
    "TODO: implement color weighting, like in Richard Zhang et al.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "kagX1JnwGF2o"
   },
   "outputs": [],
   "source": [
    "def colorization_loss(y_true, y_pred):\n",
    "  \"\"\" |y_true|: Our true colors. An array (batch_size, H, W) with entries \n",
    "                specifying one of the buckets that pixel's color is in.\n",
    "      |y_pred|: A (batch_size, H, W, 259) volume with last dimension a\n",
    "                softmax over bucket probabilities.\n",
    "  \n",
    "      This loss involves computing the softmax cross-entropy over pixel's\n",
    "        predicted color bucket, over all images in the batch.\n",
    "  \"\"\"\n",
    "  # softmax cse with logits for each pixel\n",
    "  \n",
    "  # https://www.tensorflow.org/api_docs/python/tf/contrib/layers/flatten\n",
    "  y_true_flat = tf.contrib.layers.flatten(y_true)\n",
    "  y_pred_flat = tf.contrib.layers.flatten(y_pred)\n",
    "  # Turns into one-hot representation\n",
    "  y_true_cat = to_categorical(y_true_flat, num_classes=NUM_BUCKETS)\n",
    "  \n",
    "  return categorical_crossentropy(y_true_cat, y_pred_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BO3Vi_Mey7R-"
   },
   "source": [
    "## Defining our model\n",
    "We initialize the first four layers of our CNN to the VGG16's pretrained layers, and freeze them. This transfer learning will help us "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "GwG4zlyDBXE0"
   },
   "outputs": [],
   "source": [
    "def RainbowNetModel():\n",
    "  # THE MEAT OF THE CODE\n",
    "  \n",
    "  embed_input = Input(shape=(1000,))\n",
    "  encoder_input = Input(shape=(224, 224, 1,)) # SHAPE WILL CHANGE, probably\n",
    "\n",
    "  \n",
    "  \"\"\"\n",
    "  #Encoder\n",
    "  \n",
    "  encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\n",
    "  encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "  encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "  encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "  encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "  encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "  encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "  encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "\n",
    "  #Fusion\n",
    "  fusion_output = RepeatVector(32 * 32)(embed_input) \n",
    "  fusion_output = Reshape(([32, 32, 1000]))(fusion_output)\n",
    "  fusion_output = concatenate([encoder_output, fusion_output], axis=3) \n",
    "  fusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion_output) \n",
    "\n",
    "  #Decoder\n",
    "  decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\n",
    "  decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "  decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "  decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "  decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "  decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "  decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
    "  decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "  \"\"\"\n",
    "  \n",
    "  model = Model(inputs=[encoder_input, embedding_input], outputs=decoder_output)\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "D9faritUCfc3"
   },
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "  model_json = model.to_json()\n",
    "  with open(model_chkpt + model_name + \".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "  model.save_weights(model_chkpt + model_name + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AUNILyqwO1LF"
   },
   "outputs": [],
   "source": [
    "def load_existing_model():\n",
    "  weights_path = model_chkpt + model_name + \".h5\"\n",
    "\n",
    "  if not os.path.isfile(weights_path):\n",
    "    print(\"The model at path %s was not found.\" % weights_path)\n",
    "    quit()\n",
    "    \n",
    "  model = RainbowNetModel()\n",
    "  rainbowModel.load_weights(weights_path)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8iMohPPAmMqL"
   },
   "source": [
    "## Time to train the model!\n",
    "Now we can run our model. It will save its parameters after every training session.\n",
    "\n",
    "If you're looking to only predict, run the cell after this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JlWI0B-DEZHo"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-936700860b3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimages_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-e65b0f9af2b1>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     11\u001b[0m   \"\"\"\n\u001b[1;32m     12\u001b[0m   \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# PIL image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# np.array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/train/'"
     ]
    }
   ],
   "source": [
    "images_train = load_data(train_dir)\n",
    "X_train, Y_train = preprocess_data(images_train)\n",
    "\n",
    "images_test = load_data(test_dir)\n",
    "X_test, Y_test = preprocess_data(images_test)\n",
    "\n",
    "# Run the model!\n",
    "rainbowModel = RainbowNetModel()\n",
    "\n",
    "rainbowModel.compile(optimizer='adam', \n",
    "                     loss=colorization_loss,\n",
    "                     metrics=['top_k_categorical_accuracy'])\n",
    "\n",
    "rainbowModel.fit(x=X_train, y=Y_train,\n",
    "                 epochs=N_EPOCHS,\n",
    "                 batch_size=BATCH_SIZE)\n",
    "\n",
    "save_model(rainbowModel)\n",
    "\n",
    "# Get predictions after we've trained.\n",
    "predictions = rainbowModel.evaluate(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wOcWNQ9SOZWV"
   },
   "source": [
    "## Predict using the model\n",
    "If you don't want to train, but only use the saved model to predict something, run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "zxW_idLSNl8F"
   },
   "outputs": [],
   "source": [
    "X_test, Y_test = load_data(test_dir)\n",
    "\n",
    "rainbowModel = load_existing_model()\n",
    "\n",
    "predictions = rainbowModel.evaluate(X_test, Y_test)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "rainbownet_v1.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
